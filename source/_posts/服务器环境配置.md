---
title: 服务器环境配置
date: 2018-01-04 17:16:47
tags: [this_site, lincolnzjx]
---

## 实验室服务器背景
实验室服务器连接的方式是**one-to-many**，即一台中转服务器跟着一个GPU服务器集群， 在服务器上跑程序要经过两步
1. 借助ssh从**本地电脑**登陆**中转服务器**
2. 借助ssh从**中转服务器**登陆**配置GPU的特定服务器**

具体的账号密码咨询实验室服务器管理人员。注意到**中转服务器**有两个功能
1. 提供中转的渠道，登陆之后可以选择特定的GPU服务器
2. **mount**在中转服务器上的文件也会映射到GPU服务器上
  使用到GPU的程序一定要在登陆GPU服务器之后再跑

## 实验室服务器配置
因为服务器为了兼容更多的程序，包的升级比较缓慢，普通用户是不能使用管理员的命令的！这时候我们需要配置自己的环境

#### Python + Tensorflow
推荐使用**Anaconda**来创建需要的环境。一个不需要管理员权限的**Python Data Science Platform**，实际上是将anaconda的python写入系统环境变量并且优先与系统自带的python实现目的的。我们可以用它来创建一个虚拟环境，指定需要的**Python版本**以及安装特定的包。

```
# 建议先在本地下载，然后通过scp传输到服务器上，服务器连接外网的网速贼慢！！
axel https://repo.continuum.io/archive/Anaconda3-5.0.1-Linux-x86_64.sh
# 安装anaconda并且更新，python3=3.6
bash Anaconda3-5.0.1-Linux-x86_64.sh
# 在~/.bashrc中添加以下这句，使得conda加入系统环境变量，方能被使用
. /home/path_to_your_anaconda/etc/profile.d/conda.sh
# 再升级anaconda
conda update anaconda
```

然后安装在创建的虚拟环境下Tensorflow，类似virtualenv，此处文件夹命名为tf35，指的是我们此处采用的是python3.5（不安装最新版本是因为实验室的cudnn只支持8.0，只有python35对应的tensorflow能兼容）

```bash
conda create -n tf35 python=3.5
conda activate tf35
pip install tensorflow-gpu
```



## 实验室服务器代码运行

假设我们成功完成以上设置且沿用了上面的命名。运行代码完整流程如下

1. ssh登陆到中转服务器
2. 再ssh登陆到GPU服务器（192.168.1.x, x在4-26之间）
3. 使用以下代码查看GPU是否空闲，不行的话退出到中转服务器上（**exit**），再选择另一台GPU服务器

```bash
nvidia-smi
```

4. 运行以下代码，开启**python3.5**虚拟环境，这样才能运行有关tensotflow的代码

```bash
conda activate tf35
```

5. 代码或者数据集可以通过**git**或者**scp**或者**ftp**（感谢实验室同学提醒）上传到服务器，然后在代码目录运行

```python
python path/to/code
```



## 一些已有的数据集存放

存放路径**暂定**为, 后期可能会再调整。建议实验室的同学把新下载的数据集也放在该目录下，好人一生平安🙈。
```
/home/share2/MIAGroup
```

数据集有 

|             数据集              |                    详细                    |  大小量级  |
| :--------------------------: | :--------------------------------------: | :----: |
|          chest-xray          |                    胸透                    |  10G+  |
|            cifar             |            cifar10, cifar100             | 150MB+ |
| ICIAR2018_BACH_Challenge.zip |               breast-xtay                |  10G+  |
|           synapse            |                  brain?                  |  20G+  |
|   ILSVRC(ImageNet Images)    | ILSVRC2012\*<br>ILSVRC2015_CLS-LOC.tar.gz<br>ILSVRC2017_CLS-LOC.tar.gz | 100G+  |

ps. 如果下载国外数据集网速又比较**捉急**，欢迎找**LincolnZjx**（嗯，有特效）

## 科学上网Tips

两种做法
第一种：下载Lantern，安装即可使用。
第二种：借助ss和一台国外的服务器。简单来说就是，本地数据经过ss的加密发送给国外的服务器，服务器上有ss服务端接受并解密查询，再转发查询结果回来。

以下简略介绍第二种做法

#### 具体流程
1. 租服务器
2. 配置服务器
3. 配置客户端

#### 服务端
DO和Vultr的服务器都不错，HK，JP，SG的节点会比较快。搭建的时候只需要运行

```
apt-get install python-pip
pip install git+https://github.com/shadowsocks/shadowsocks.git@master
sudo touch /etc/shadowsocks.json 
ssserver -c /etc/shadowsocks.json -d
```

以下是服务端的json配置文件的做法

```
{
    "server":"服务器自己的ip",
    "local_address": "127.0.0.1",
    "local_port":1080,
    "port_password":{
	"你想使用到服务器端口":"你想设置的密码"
    },
    "timeout":300,
    "method":"aes-256-cfb",
    "fast_open": false
}
```
#### 客户端设置
以下演示的是**Ubuntu**上的做法

```
sudo apt install python-pip
pip install git+https://github.com/shadowsocks/shadowsocks.git@master
sudo touch /etc/shadowsocks.json # 该文件存放的是ss登陆服务器的密码，是由服务器端的配置文件决定的
sslocal -c /etc/shadowsocks.json
```

以下是一个通用的客户端shadowsocks.json配置文件的做法, server填的是服务器的ip，server_port是服务器ss服务端监听的端口，password自己设定。

```
{
    "server":"",
    "server_port": "",
    "local_port":1080,
    "password":"",
    "timeout":300,
    "method":"aes-256-cfb",
    "fast_open": false
}
```

### 更新日志

* 2018.1.15 添加服务器运行代码的流程


* 2018.1.10 修改conda create语句


* 2018.1.5 添加conda生效的语句
* 2018.1.4 创建文章

### 参考资料
1. [tensorflow官网](https://www.tensorflow.org/install/install_linux#installing_with_anaconda)
2. [github ss](不能说)


